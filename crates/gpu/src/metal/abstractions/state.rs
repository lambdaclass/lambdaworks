//! Metal state management for GPU operations.
//!
//! This module provides abstractions for managing Metal device state, including
//! device initialization, shader library loading, and buffer management.
//!
//! Inspired by:
//! - Original lambdaworks Metal implementation (pre-PR#993)
//! - ICICLE's multi-backend architecture
//! - ministark's Metal GPU implementation

use super::errors::MetalError;
use metal::{
    Buffer, CommandBufferRef, CommandQueue, ComputeCommandEncoderRef, ComputePipelineState, Device,
    Library, MTLResourceOptions,
};
use std::{ffi, mem};

/// Pre-compiled Metal shader library.
/// This is generated by build.rs from the .metal shader files.
const LIB_DATA: &[u8] = include_bytes!("../../../../math/src/gpu/metal/lib.metallib");

/// Structure for abstracting basic calls to a Metal device and saving the state.
///
/// Used for implementing GPU parallel computations on Apple Silicon and other
/// Metal-compatible GPUs.
///
/// # Example
///
/// ```ignore
/// use lambdaworks_gpu::metal::abstractions::state::MetalState;
///
/// let state = MetalState::new(None)?;
/// let pipeline = state.setup_pipeline("my_kernel")?;
/// ```
pub struct MetalState {
    /// The Metal device (GPU) being used.
    pub device: Device,
    /// The compiled shader library containing all kernels.
    pub library: Library,
    /// Command queue for submitting work to the GPU.
    pub queue: CommandQueue,
}

impl MetalState {
    /// Creates a new Metal state with an optional `device` (GPU).
    ///
    /// If `None` is passed, it will use the system's default Metal device.
    ///
    /// # Errors
    ///
    /// Returns `MetalError::DeviceNotFound` if no Metal-compatible GPU is available.
    /// Returns `MetalError::LibraryError` if the shader library cannot be loaded.
    pub fn new(device: Option<Device>) -> Result<Self, MetalError> {
        let device = match device {
            Some(d) => d,
            None => Device::system_default().ok_or(MetalError::DeviceNotFound)?,
        };

        let library = device
            .new_library_with_data(LIB_DATA)
            .map_err(|e| MetalError::LibraryError(e.to_string()))?;

        let queue = device.new_command_queue();

        Ok(Self {
            device,
            library,
            queue,
        })
    }

    /// Creates a compute pipeline for a kernel function.
    ///
    /// The `kernel_name` must match a function defined in the Metal shader library.
    ///
    /// # Errors
    ///
    /// Returns `MetalError::FunctionError` if the kernel is not found.
    /// Returns `MetalError::PipelineError` if pipeline creation fails.
    pub fn setup_pipeline(&self, kernel_name: &str) -> Result<ComputePipelineState, MetalError> {
        let kernel = self
            .library
            .get_function(kernel_name, None)
            .map_err(|e| MetalError::FunctionError(format!("{}: {}", kernel_name, e)))?;

        self.device
            .new_compute_pipeline_state_with_function(&kernel)
            .map_err(|e| MetalError::PipelineError(e.to_string()))
    }

    /// Allocates `length` elements of type `T` in shared memory between CPU and GPU.
    ///
    /// Uses `StorageModeShared` for unified memory access on Apple Silicon.
    pub fn alloc_buffer<T>(&self, length: usize) -> Buffer {
        let size = mem::size_of::<T>();

        self.device.new_buffer(
            (length * size) as u64,
            MTLResourceOptions::StorageModeShared,
        )
    }

    /// Allocates a buffer initialized with `data` in shared memory.
    ///
    /// Uses `StorageModeShared` for unified memory access on Apple Silicon.
    pub fn alloc_buffer_data<T>(&self, data: &[T]) -> Buffer {
        self.device.new_buffer_with_data(
            data.as_ptr() as *const ffi::c_void,
            mem::size_of_val(data) as u64,
            MTLResourceOptions::StorageModeShared,
        )
    }

    /// Creates a command buffer and compute encoder for a pipeline.
    ///
    /// Optionally binds `buffers` to the encoder at the specified indices.
    ///
    /// # Returns
    ///
    /// A tuple of (command_buffer, command_encoder) for issuing GPU commands.
    pub fn setup_command(
        &self,
        pipeline: &ComputePipelineState,
        buffers: Option<&[(u64, &Buffer)]>,
    ) -> (&CommandBufferRef, &ComputeCommandEncoderRef) {
        let command_buffer = self.queue.new_command_buffer();
        let command_encoder = command_buffer.new_compute_command_encoder();
        command_encoder.set_compute_pipeline_state(pipeline);

        if let Some(buffers) = buffers {
            for (index, buffer) in buffers.iter() {
                command_encoder.set_buffer(*index, Some(buffer), 0);
            }
        }

        (command_buffer, command_encoder)
    }

    /// Retrieves the contents of a Metal buffer as a vector.
    ///
    /// # Safety
    ///
    /// This function reads raw memory from the buffer. The caller must ensure that:
    /// - The buffer contains valid data of type `T`
    /// - The buffer was allocated with enough space for the data
    /// - The data has been synchronized (command buffer completed)
    pub fn retrieve_contents<T: Copy>(buffer: &Buffer) -> Vec<T> {
        let ptr = buffer.contents() as *const T;
        let len = buffer.length() as usize / mem::size_of::<T>();
        // Safety: Metal buffers with StorageModeShared are in unified memory
        // and properly aligned. The caller ensures synchronization.
        unsafe { std::slice::from_raw_parts(ptr, len).to_vec() }
    }
}

/// Helper function to convert a reference to a void pointer for Metal API.
#[inline]
pub fn void_ptr<T>(v: &T) -> *const ffi::c_void {
    v as *const T as *const ffi::c_void
}
